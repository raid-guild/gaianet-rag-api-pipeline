{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import importlib.util\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pathway as pw\n",
    "from pathway.xpacks.llm import embedders, parsers, splitters, vector_store\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "# from unstructured.documents.elements import Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure libmagic is available\n",
    "LIBMAGIC_AVAILABLE = bool(importlib.util.find_spec(\"magic\"))\n",
    "assert LIBMAGIC_AVAILABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv.dotenv_values('.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_name = 'aave'\n",
    "prop_order_by = 'asc'\n",
    "api_key = config['BOARDROOM_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoardroomAPI(pw.Schema):\n",
    "    data: pw.Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Parser UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "from io import BytesIO\n",
    "from pathway.optional_import import optional_imports\n",
    "# from typing import TYPE_CHECKING, Any, Literal\n",
    "\n",
    "from typing import Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomParseUnstructured(pw.UDF):\n",
    "    \"\"\"\n",
    "    Parse document using `https://unstructured.io/ <https://unstructured.io/>`_.\n",
    "\n",
    "    All arguments can be overridden during UDF application.\n",
    "\n",
    "    Args:\n",
    "        - mode: single, elements or paged.\n",
    "          When single, each document is parsed as one long text string.\n",
    "          When elements, each document is split into unstructured's elements.\n",
    "          When paged, each pages's text is separately extracted.\n",
    "        - post_processors: list of callables that will be applied to all extracted texts.\n",
    "        - **unstructured_kwargs: extra kwargs to be passed to unstructured.io's `partition` function\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = \"single\",\n",
    "        post_processors: list[Callable] | None = None,\n",
    "        **unstructured_kwargs: Any,\n",
    "    ):\n",
    "        with optional_imports(\"xpack-llm-docs\"):\n",
    "            import unstructured.partition.auto  # noqa:F401\n",
    "\n",
    "        super().__init__()\n",
    "        _valid_modes = {\"single\", \"elements\", \"paged\"}\n",
    "        if mode not in _valid_modes:\n",
    "            raise ValueError(\n",
    "                f\"Got {mode} for `mode`, but should be one of `{_valid_modes}`\"\n",
    "            )\n",
    "\n",
    "        self.kwargs = dict(\n",
    "            mode=mode,\n",
    "            post_processors=post_processors or [],\n",
    "            unstructured_kwargs=unstructured_kwargs,\n",
    "        )\n",
    "\n",
    "    # # `links` and `languages` in metadata are lists, so their content should be added.\n",
    "    # # We don't want return `coordinates`, `parent_id` and `category_depth` - these are\n",
    "    # # element specific (i.e. they can differ for elements on the same page)\n",
    "    # def _combine_metadata(self, left: dict, right: dict) -> dict:\n",
    "    #     result = {}\n",
    "    #     links = left.pop(\"links\", []) + right.pop(\"links\", [])\n",
    "    #     languages = list(set(left.pop(\"languages\", []) + right.pop(\"languages\", [])))\n",
    "    #     result.update(left)\n",
    "    #     result.update(right)\n",
    "    #     result[\"links\"] = links\n",
    "    #     result[\"languages\"] = languages\n",
    "    #     result.pop(\"coordinates\", None)\n",
    "    #     result.pop(\"parent_id\", None)\n",
    "    #     result.pop(\"category_depth\", None)\n",
    "    #     return result\n",
    "\n",
    "    # def __wrapped__(self, contents: bytes, **kwargs) -> list[tuple[str, dict]]:\n",
    "    def __wrapped__(self, contents: bytes, **kwargs) -> list[dict]:\n",
    "        \"\"\"\n",
    "        Parse the given document:\n",
    "\n",
    "        Args:\n",
    "            - contents: document contents\n",
    "            - **kwargs: override for defaults set in the constructor\n",
    "\n",
    "        Returns:\n",
    "            a list of pairs: text chunk and metadata\n",
    "            The metadata is obtained from Unstructured, you can check possible values\n",
    "            in the `Unstructed documentation <https://unstructured-io.github.io/unstructured/metadata.html>`\n",
    "            Note that when `mode` is set to `single` or `paged` some of these fields are\n",
    "            removed if they are specific to a single element, e.g. `category_depth`.\n",
    "        \"\"\"\n",
    "        import unstructured.partition.auto\n",
    "\n",
    "        kwargs = {**self.kwargs, **kwargs}\n",
    "\n",
    "        elements = unstructured.partition.auto.partition(\n",
    "            file=BytesIO(contents), **kwargs.pop(\"unstructured_kwargs\")\n",
    "        )\n",
    "\n",
    "        post_processors = kwargs.pop(\"post_processors\")\n",
    "        for element in elements:\n",
    "            for post_processor in post_processors:\n",
    "                element.apply(post_processor)\n",
    "\n",
    "        mode = kwargs.pop(\"mode\")\n",
    "\n",
    "        if kwargs:\n",
    "            raise ValueError(f\"Unknown arguments: {', '.join(kwargs.keys())}\")\n",
    "\n",
    "        if mode == \"elements\":\n",
    "            # docs: list[tuple[str, dict]] = list()\n",
    "            # for element in elements:\n",
    "            #     # NOTE(MthwRobinson) - the attribute check is for backward compatibility\n",
    "            #     # with unstructured<0.4.9. The metadata attributed was added in 0.4.9.\n",
    "            #     # if hasattr(element, \"metadata\"):\n",
    "            #     #     metadata = element.metadata.to_dict()\n",
    "            #     # else:\n",
    "            #     #     metadata = {}\n",
    "            #     # if hasattr(element, \"category\"):\n",
    "            #     #     metadata[\"category\"] = element.category\n",
    "            #     # docs.append((str(element), metadata))\n",
    "            docs: list[dict] = [el.to_dict() for el in elements]\n",
    "        # elif mode == \"paged\":\n",
    "        #     text_dict: dict[int, str] = {}\n",
    "        #     meta_dict: dict[int, dict] = {}\n",
    "\n",
    "        #     for idx, element in enumerate(elements):\n",
    "        #         if hasattr(element, \"metadata\"):\n",
    "        #             metadata = element.metadata.to_dict()\n",
    "        #         else:\n",
    "        #             metadata = {}\n",
    "        #         page_number = metadata.get(\"page_number\", 1)\n",
    "\n",
    "        #         # Check if this page_number already exists in docs_dict\n",
    "        #         if page_number not in text_dict:\n",
    "        #             # If not, create new entry with initial text and metadata\n",
    "        #             text_dict[page_number] = str(element) + \"\\n\\n\"\n",
    "        #             meta_dict[page_number] = metadata\n",
    "        #         else:\n",
    "        #             # If exists, append to text and update the metadata\n",
    "        #             text_dict[page_number] += str(element) + \"\\n\\n\"\n",
    "        #             meta_dict[page_number] = self._combine_metadata(\n",
    "        #                 meta_dict[page_number], metadata\n",
    "        #             )\n",
    "\n",
    "        #     # Convert the dict to a list of dicts representing documents\n",
    "        #     docs = [(text_dict[key], meta_dict[key]) for key in text_dict.keys()]\n",
    "        # elif mode == \"single\":\n",
    "        #     metadata = {}\n",
    "        #     for element in elements:\n",
    "        #         if hasattr(element, \"metadata\"):\n",
    "        #             metadata = self._combine_metadata(\n",
    "        #                 metadata, element.metadata.to_dict()\n",
    "        #             )\n",
    "        #     text = \"\\n\\n\".join([str(el) for el in elements])\n",
    "        #     docs = [(text, metadata)]\n",
    "        else:\n",
    "            raise ValueError(f\"mode of {mode} not supported.\")\n",
    "        return docs\n",
    "\n",
    "    def __call__(self, contents: pw.ColumnExpression, **kwargs) -> pw.ColumnExpression:\n",
    "        \"\"\"\n",
    "        Parse the given document.\n",
    "\n",
    "        Args:\n",
    "            - contents: document contents\n",
    "            - **kwargs: override for defaults set in the constructor\n",
    "\n",
    "        Returns:\n",
    "            A column with a list of pairs for each query. Each pair is a text chunk and\n",
    "            associated metadata.\n",
    "            The metadata is obtained from Unstructured, you can check possible values\n",
    "            in the `Unstructed documentation <https://unstructured-io.github.io/unstructured/metadata.html>`\n",
    "            Note that when `mode` is set to `single` or `paged` some of these fields are\n",
    "            removed if they are specific to a single element, e.g. `category_depth`.\n",
    "        \"\"\"\n",
    "        return super().__call__(contents, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CFLAGS=\"-Wno-nullability-completeness\" if trying to install pillow-heif missingn module\n",
    "# libmagic -> Required for having libmagic working:\n",
    "# - brew install libmagic\n",
    "# - pip install python-magic-bin\n",
    "\n",
    "# parser = parsers.ParseUnstructured(mode=\"elements\")\n",
    "parser = CustomParseUnstructured(mode=\"elements\") # TODO: do we need extra cleaning function as post_processors ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pw.udf(executor=pw.udfs.async_executor())\n",
    "\n",
    "@pw.udf\n",
    "def filter_document(document: pw.Json, fields: list[str]) -> pw.Json:\n",
    "    data = { **document.as_dict() }\n",
    "    # data = { \"refId\": document[\"refId\"] }\n",
    "    for field in fields:\n",
    "        if field in data:\n",
    "            data.pop(field)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_logger = logging.getLogger(\"unstructured\")\n",
    "# u_logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protocol(pw.Schema):\n",
    "    cname: str\n",
    "    name: str\n",
    "    categories: str\n",
    "    is_enabled: bool\n",
    "    active_on_website: bool\n",
    "    total_proposals: int\n",
    "    total_votes: int\n",
    "    unique_voters: int\n",
    "    # tokens: list[object]\n",
    "    ptype: str\n",
    "    # delegated_support: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protocol_mapper(raw_data: bytes) -> bytes:\n",
    "    # logger.info(raw_data.decode())\n",
    "    data = json.loads(raw_data.decode())[\"data\"]\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"cname\": data[\"cname\"],\n",
    "            \"name\": data[\"name\"],\n",
    "            \"categories\": \",\".join(data[\"categories\"]),\n",
    "            \"is_enabled\": data[\"isEnabled\"],\n",
    "            \"active_on_website\": data[\"activeOnWebsite\"],\n",
    "            \"total_proposals\": data[\"totalProposals\"],\n",
    "            \"total_votes\": data[\"totalVotes\"],\n",
    "            \"unique_voters\": data[\"uniqueVoters\"],\n",
    "            \"ptype\": data[\"type\"],\n",
    "        }\n",
    "    ).encode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "protocol = pw.io.http.read(\n",
    "    f\"https://api.boardroom.info/v1/protocols/{protocol_name}?key={api_key}\",\n",
    "    method='GET',\n",
    "    headers={\"Accept\": \"application/json\"},\n",
    "    # format=\"raw\",\n",
    "    schema=Protocol,\n",
    "    response_mapper=protocol_mapper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Old schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Proposal(pw.Schema):\n",
    "#     protocol: str\n",
    "#     ref_id: str\n",
    "#     pid: str\n",
    "#     title: str\n",
    "#     content: str\n",
    "#     adapter: str\n",
    "#     proposer: str\n",
    "#     total_votes: int\n",
    "#     block_number: int\n",
    "#     external_url: str\n",
    "#     start_timestamp: int\n",
    "#     end_timestamp: int\n",
    "#     current_state: str\n",
    "#     # results: list[dict] # TODO\n",
    "#     ptype: str\n",
    "#     summary: str\n",
    "#     privacy: str\n",
    "#     # executables: dict\n",
    "#     tx_hash: str\n",
    "#     quorum: int\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def coalesce(data: dict, key: str, fallback: str = ''):\n",
    "#     return data[key] if key in data else fallback\n",
    "\n",
    "# def proposal_mapper(raw_data: bytes) -> bytes:\n",
    "#     json_data = json.loads(raw_data.decode())\n",
    "#     data_records = json_data[\"data\"]\n",
    "#     next_cursor = json_data[\"nextCursor\"]\n",
    "#     # return json.dumps([\n",
    "#     #     {\n",
    "#     #         \"protocol\": coalesce(data, \"protocol\"),\n",
    "#     #         \"ref_id\": coalesce(data, \"refId\"),\n",
    "#     #         \"pid\": coalesce(data, \"id\"),\n",
    "#     #         \"title\": coalesce(data, \"title\"),\n",
    "#     #         \"content\": coalesce(data, \"content\"),\n",
    "#     #         \"adapter\": coalesce(data, \"adapter\"),\n",
    "#     #         \"proposer\": coalesce(data, \"proposer\"),\n",
    "#     #         \"total_votes\": coalesce(data, \"totalVotes\"),\n",
    "#     #         \"block_number\": coalesce(data, \"blockNumber\"),\n",
    "#     #         \"external_url\": coalesce(data, \"externalUrl\"),\n",
    "#     #         \"start_timestamp\": int(coalesce(data, \"startTimestamp\")),\n",
    "#     #         \"end_timestamp\": int(coalesce(data, \"endTimestamp\")),\n",
    "#     #         \"current_state\": coalesce(data, \"currentState\"),\n",
    "#     #         # \"results\": [{\"choice\": data[\"choices\"][choice[\"choice\"]], \"result\": choice[\"total\"]} for choice in data[\"results\"]],\n",
    "#     #         \"ptype\": coalesce(data, \"type\"),\n",
    "#     #         \"summary\": coalesce(data, \"summary\"),\n",
    "#     #         \"privacy\": coalesce(data, \"privacy\"),\n",
    "#     #         \"tx_hash\": coalesce(data, \"txHash\"),\n",
    "#     #         \"quorum\": coalesce(data, \"quorum\"),\n",
    "#     #     } for data in data_records\n",
    "#     data = data_records[0]\n",
    "#     return json.dumps(\n",
    "#         {\n",
    "#             \"protocol\": coalesce(data, \"protocol\"),\n",
    "#             \"ref_id\": coalesce(data, \"refId\"),\n",
    "#             \"pid\": coalesce(data, \"id\"),\n",
    "#             \"title\": coalesce(data, \"title\"),\n",
    "#             \"content\": coalesce(data, \"content\"),\n",
    "#             \"adapter\": coalesce(data, \"adapter\"),\n",
    "#             \"proposer\": coalesce(data, \"proposer\"),\n",
    "#             \"total_votes\": coalesce(data, \"totalVotes\"),\n",
    "#             \"block_number\": coalesce(data, \"blockNumber\"),\n",
    "#             \"external_url\": coalesce(data, \"externalUrl\"),\n",
    "#             \"start_timestamp\": int(coalesce(data, \"startTimestamp\")),\n",
    "#             \"end_timestamp\": int(coalesce(data, \"endTimestamp\")),\n",
    "#             \"current_state\": coalesce(data, \"currentState\"),\n",
    "#             # \"results\": [{\"choice\": data[\"choices\"][choice[\"choice\"]], \"result\": choice[\"total\"]} for choice in data[\"results\"]],\n",
    "#             \"ptype\": coalesce(data, \"type\"),\n",
    "#             \"summary\": coalesce(data, \"summary\"),\n",
    "#             \"privacy\": coalesce(data, \"privacy\"),\n",
    "#             \"tx_hash\": coalesce(data, \"txHash\"),\n",
    "#             \"quorum\": coalesce(data, \"quorum\"),\n",
    "#         }\n",
    "#     ).encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pw.udf\n",
    "def append_parent_id(content: pw.Json, parent_id: str) -> pw.Json:\n",
    "    data = { \"parent_id\": parent_id, **content.as_dict() }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = pw.io.http.read(\n",
    "    f\"https://api.boardroom.info/v1/protocols/{protocol_name}/proposals?key={api_key}&orderByIndexedAt{prop_order_by}\",\n",
    "    method='GET',\n",
    "    headers={\"Accept\": \"application/json\"},\n",
    "    format=\"json\",\n",
    "    schema=BoardroomAPI\n",
    "    # schema=Proposal,\n",
    "    # response_mapper=proposal_mapper\n",
    ")\n",
    "proposals = proposals.flatten(proposals.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = proposals.with_columns(\n",
    "    refId=pw.this.data.get(\"refId\", default=pw.Json(\"\")).as_str(),\n",
    "    title=pw.this.data.get(\"title\", default=pw.Json(\"\")).as_str(),\n",
    "    # metadata=pw.apply_with_type(lambda x: filter_document(x, [\"refId\", \"title\", \"content\"]), dict, pw.this.data),\n",
    "    # metadata=pw.apply_with_type(lambda x: filter_document(x), dict, pw.this.data),\n",
    "    metadata=filter_document(pw.this.data, [\"refId\", \"title\", \"content\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_table = proposals.select(\n",
    "    element_id=pw.this.refId,\n",
    "    text=pw.this.title,\n",
    "    metadata=pw.this.metadata,\n",
    "    type=\"Title\"\n",
    "    # content=build_main_element(pw.this.refId, pw.this.title, pw.this.metadata),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_contents = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposal content\n",
    "proposal_contents = proposals.select(\n",
    "    refId=pw.this.refId,\n",
    "    # content=pw.apply_with_type(lambda x: f\"{x}\".encode() if x else b\"\", bytes, pw.this.data.get(\"content\", default=None)),\n",
    "    content=parser(pw.apply_with_type(lambda x: f\"{x.as_str()}\".encode() if x else b\"\", bytes, pw.this.data.get(\"content\", default=None))),\n",
    ")\n",
    "proposal_contents = proposal_contents.flatten(pw.this.content)\n",
    "# # proposals = proposals.select(refId=pw.this.refId, title=pw.this.title, text=pw.this.content[0], metadata=pw.this.content[1])\n",
    "# # proposals = proposals.select(refId=pw.this.refId, title=pw.this.title, text=pw.this.document['text'].as_str(), document=pw.this.document)\n",
    "# proposals = proposals.select(refId=pw.this.refId, document=pw.this.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_contents.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.file_utils.filetype import detect_filetype, is_json_processable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# For now, all text data is being recognized as txt files instead of md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cheking file type detection during partition\n",
    "\n",
    "# @pw.udf\n",
    "# def detect(data: pw.Json) -> str:\n",
    "#     encoded = data.as_str().encode()\n",
    "#     filetype = detect_filetype(file=BytesIO(encoded))\n",
    "#     return str(filetype)\n",
    "    \n",
    "\n",
    "# meta = proposals.select(\n",
    "#     metadata=pw.this.data.get(\"content\", default=None)\n",
    "# )\n",
    "# meta = meta.with_columns(\n",
    "#     filetype=detect(pw.this.metadata),\n",
    "# )\n",
    "# meta.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONAccumulator(pw.BaseCustomAccumulator):\n",
    "  def __init__(self, initialData: pw.Json):\n",
    "    self.data: list[dict] = list()\n",
    "    self.value: dict = { **initialData.as_dict() }\n",
    "\n",
    "  @classmethod\n",
    "  def from_row(self, row):\n",
    "    [val] = row\n",
    "    return JSONAccumulator(val)\n",
    "\n",
    "  def update(self, other):\n",
    "    self.data.append(other.value)\n",
    "\n",
    "  def compute_result(self) -> list[dict]:\n",
    "    return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_acc = pw.reducers.udf_reducer(JSONAccumulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = proposal_contents.groupby(proposal_contents.refId).reduce(proposal_contents.refId, contents=json_acc(proposal_contents.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.io.jsonlines.write(grouped, \"proposalsc.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatening contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_contents = proposal_contents.select(\n",
    "    element_id=pw.this.content.get(\"element_id\", default=pw.Json(\"\")).as_str(),\n",
    "    text=pw.this.content.get(\"text\", default=pw.Json(\"\")).as_str(),\n",
    "    metadata=append_parent_id(pw.this.content[\"metadata\"], pw.this.refId),\n",
    "    type=pw.this.content.get(\"type\", default=pw.Json(\"\")).as_str(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_contents.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_table = proposals_table.concat_reindex(proposal_contents)\n",
    "proposals_table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermediate storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.io.jsonlines.write(proposals_table, \"proposals.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pw.debug.compute_and_print(proposals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More on chunking parameters https://docs.unstructured.io/open-source/core-functionality/chunking\n",
    "combine_text_under_n_chars: Optional[int] = None\n",
    "include_orig_elements: Optional[bool] = None\n",
    "max_characters: Optional[int] = None\n",
    "multipage_sections: Optional[bool] = None\n",
    "new_after_n_chars: Optional[int] = None\n",
    "overlap: Optional[int] = None\n",
    "overlap_all: Optional[bool] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: UDF for chukning\n",
    "# call chunk_by_title(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_API_KEY = \"\"\n",
    "EMBEDDINGS_MODEL = \"Meta-Llama-3-8B-Instruct-Q5_K_M\"\n",
    "EMBEDDINGS_API_BASE = \"https://llama3.gaianet.network/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pw.udf(\n",
    "        # cache_strategy=pw.udfs.DefaultCache(),\n",
    "        executor=pw.udfs.async_executor(\n",
    "            # capacity=5,\n",
    "            retry_strategy=pw.asynchronous.udfs.FixedDelayRetryStrategy(delay_ms=10000)\n",
    "        ),\n",
    "        return_type=str\n",
    "    )\n",
    "def embedder_call(document: str) -> str:\n",
    "    returned = embedding(\n",
    "        input=[document],\n",
    "        # dimensions=embedding_dimension,\n",
    "        api_key=EMBEDDINGS_API_KEY,\n",
    "        model=EMBEDDINGS_MODEL,\n",
    "        api_base=EMBEDDINGS_API_BASE,\n",
    "        custom_llm_provider=\"openai\" # litellm will use the openai.ChatCompletion to make the request\n",
    "    )\n",
    "\n",
    "    result = returned.data[0][\"embedding\"]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: data sources should match schema (data: bytes, _metadata: any)\n",
    "\n",
    "# doc_store = VectorStoreServer(\n",
    "#     # *data_sources(configuration[\"sources\"]),\n",
    "#     # *data_sources, # TODO:\n",
    "#     embedder=embedder,\n",
    "#     # splitter=splitters.TokenCountSplitter(max_tokens=400),\n",
    "#     parser=parser,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = KNNIndex(\n",
    "#     enriched_documents.vector, enriched_documents, n_dimensions=embedding_dimension\n",
    "# )\n",
    "# ...\n",
    "# query += query.select(\n",
    "#     vector=embedder(pw.this.query),\n",
    "# )\n",
    "\n",
    "# query_context = query + index.get_nearest_items(\n",
    "#     query.vector, k=3, collapse_rows=True\n",
    "# ).select(documents_list=pw.this.chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voter_mapper(raw_data: bytes) -> bytes:\n",
    "    data = json.loads(raw_data.decode())[\"data\"]\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"address\": data[\"address\"],\n",
    "            \"totalVotesCast\": data[\"protocols\"][0]['totalVotesCast'],\n",
    "            \"lastVoteCast\": data[\"protocols\"][0][\"lastVoteCast\"],\n",
    "            \"firstVoteCast\": data[\"protocols\"][0][\"firstVoteCast\"],\n",
    "            \"totalPowerCast\": data[\"protocols\"][0][\"totalPowerCast\"],\n",
    "            \"lastCastPower\": data[\"protocols\"][0][\"lastCastPower\"],\n",
    "            \n",
    "        }\n",
    "    ).encode()\n",
    "\n",
    "class Voter(pw.Schema):\n",
    "    address: str\n",
    "    firstVoteCast: int\n",
    "    lastVoteCast: int\n",
    "    totalVotesCast: int\n",
    "    protocolVoteCast: str\n",
    "    totalPowerCast: float\n",
    "    lastCastPower: float\n",
    "    # otherProtocols: str\n",
    "    \n",
    "class Voters(pw.Schema):\n",
    "    data: pw.Json\n",
    "\n",
    "## TODO: fix this voter -> voters as data : voters[] @santiago\n",
    "    \n",
    "voters = pw.io.http.read(\n",
    "    f\"https://api.boardroom.info/v1/protocols/{protocol_name}/voters?key={api_key}\",\n",
    "    method='GET',\n",
    "    headers={\"Accept\": \"application/json\"},\n",
    "    format=\"json\",\n",
    "    schema=Voters,\n",
    "    # response_mapper=voter_mapper\n",
    ")\n",
    "\n",
    "voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = voters.flatten(voters.data)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_all_protocols(protocols: pw.Json):\n",
    "    return \"\".join(protocol[\"protocol\"].as_str() + \", \" for protocol in protocols)\n",
    "\n",
    "def mapper(protocols: pw.Json):\n",
    "    for protocol in protocols:\n",
    "        if protocol[\"protocol\"].as_str() == \"aave\":\n",
    "            return protocol\n",
    "\n",
    "z = x.select(\n",
    "    protocol=pw.apply(mapper, pw.this.data[\"protocols\"]),\n",
    "    all_protocols=pw.apply(map_all_protocols, pw.this.data[\"protocols\"]),\n",
    ")\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pw.debug.compute_and_print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture --no-display\n",
    "pw.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
