# GaiaNet RAG API Pipeline

`rag-api-pipeline` is a Python-based data pipeline tool that allows you to easily generate a vector knowledge base from any REST API data source. The
resulting database snapshot can then be plugged into a Gaia node's LLM model with a prompt and provide contextual responses to user queries using RAG 
(Retrieval Augmented Generation).

The following sections help you quickly set up and execute the pipeline on your REST API. If you're looking for more in-depth information about how to use 
this tool, the tech stack and/or how it works under the hood, check the content menu on the left.

## System Requirements

- Python 3.11.x
- Poetry ([Docs](https://python-poetry.org/docs/))
  - (Optional): a Python virtual environment manager of your preference (e.g. conda, venv)
- Qdrant vector database ([Docs](https://qdrant.tech/documentation/))
  - (Optional): Docker to spin up a local container
- LLM model provider (e.g. [spin up your own Gaia node](/cli/node-deployment) or pick one from the [GaiaNet public network](https://www.gaianet.ai/chat))
  - An Embeddings model (e.g. [Nomic-embed-text-v1.5](https://huggingface.co/gaianet/Nomic-embed-text-v1.5-Embedding-GGUF/tree/main?show_file_info=nomic-embed-text-v1.5.f16.gguf))

## Setup Instructions

::::steps
### Clone this repository

Git clone or download this repository to your local machine.

```bash [Terminal]
git clone https://github.com/raid-guild/gaianet-rag-api-pipeline.git
```

### Install the Pipeline CLI 

It is recommended to activate your [own virtual environment](https://python-poetry.org/docs/basic-usage/#using-your-virtual-environment). 
Then, navigate to the directory where this repository was cloned/download and execute the following command to install the `rag-api-pipeline` CLI:

```bash [Terminal]
cd gaianet-rag-api-pipeline
pip install -e .
```

### Setup the Pipeline Configuration

Run the following command to start the pipeline setup wizard. You can use the default configuration settings or customize it for your specific needs.
Check the [CLI Reference](/cli/reference) page for more details:

```bash [Terminal]
rag-api-pipeline setup
```
::::

Visit the [Setup Wizard](/cli/setup) page for more information.

## Run a demo RAG API pipeline

A quick demo that extracts data from the Boardroom API can be executed by running the following command:

```bash [Terminal]
rag-api-pipeline run all config/boardroom_api_pipeline.yaml config/boardroom_openapi.yaml
```

You are required two specify two main arguments to the pipeline:
- The path to the OpenAPI specification file (e.g. `config/boardroom_openapi.yaml`): the OpenAPI spec for the REST API data source 
you're looking to extract data from.
- The path to the API pipeline manifest file (e.g. `config/boardroom_api_pipeline.yaml`): a YAML file that defines API endpoints you're 
looking to extract data from, among other parameters (more details in the next section).

Once the pipeline execution is completed, you'll find the vector database snapshot and extracted/processed datasets under the `output/molochdao_boardroom_api` folder.

## Define your own API Pipeline manifest

Now it's time to define the pipeline manifest for the REST API you're looking to extract data from. Make sure you get the OpenAPI specification 
for the API you're targeting. Check the 
[Defining an API Pipeline Manifest](/manifest-definition) page for details on how to get the OpenAPI spec and define an API pipeline manifest, 
or take a look at the in-depth review of the sample manifests available in the [API Examples](/apis) section.

## Using the Pipeline CLI

Once you have both the API pipeline manifest and OpenAPI spec files, you're ready to start using the `rag-api-pipeline run` command to execute different tasks of the RAG pipeline, 
from extracting data from an API source to generating vector embeddings and a database snapshot. If you need more details about the parameters available 
on each task you can execute:

```bash [Terminal]
rag-api-pipeline run <command> --help
```

### Available sub-commands

Below is the list of available commands. Check the [CLI Reference](/cli/reference#run) documentation for more details:

```bash [Terminal]
# run the entire pipeline
rag-api-pipeline run all <API_MANIFEST_FILE> <OPENAPI_SPEC_FILE> [--full-refresh]
# or run using an already normalized dataset
rag-api-pipeline run from-normalized <API_MANIFEST_FILE> --normalized-data-file <jsonl-file>
# or run using an already chunked dataset
rag-api-pipeline run from-chunked <API_MANIFEST_FILE> --chunked-data-file <jsonl-file>
```
